{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b759bf",
   "metadata": {},
   "source": [
    "The majority of the data pre-processing and visualization code were adapted from Professor Harry Heorton's code\n",
    "My modification is to slighly adjust the date and range to prepare it for the next signal filtering process and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports all the packages\n",
    "import numpy as np\n",
    "import grid_set as gs\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import glob\n",
    "from numpy.fft import fft, ifft\n",
    "from scipy.fftpack import fftfreq\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### grids\n",
    "m = ccrs.SouthPolarStereo()\n",
    "GN = gs.grid_set(m)\n",
    "GN.load_grid('D:\\\\Weiyi_SWH\\\\NSIDC_gs_SH.npz')\n",
    "GN.get_grid_mask()\n",
    "\n",
    "m = ccrs.SouthPolarStereo()\n",
    "GS = gs.grid_set(m)\n",
    "GS.load_grid('D:\\\\Weiyi_SWH\\\\Polar_stereo_100km_SH.npz')\n",
    "GS.get_grid_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### nsidc class\n",
    "# This part of the code was adapted \n",
    "class NSIDC_nt():\n",
    "    def __init__(self,ppath):\n",
    "        self.name = 'NSIDC_n'\n",
    "        self.path = ppath\n",
    "# next function will take a list of dates and return an appropriately orientated arrays\n",
    "# give a \n",
    "    def get_aice(self,dates_u,verbos=False):\n",
    "        # does dates_u cover one year or more\n",
    "        # daily files\n",
    "        dimY = 316\n",
    "        dimX = 332\n",
    "        d_no = np.shape(dates_u)[0]\n",
    "        data =  np.empty([d_no, dimX, dimY])\n",
    "        for n,d in enumerate(dates_u):\n",
    "            infile = self.path+d.strftime('/%Y/')+\"nt_\"+d.strftime('%Y%m%d')+\"_*.bin\"\n",
    "            flist  = glob.glob(infile)\n",
    "            if len(flist) > 0:\n",
    "                infile = flist[0]\n",
    "            else:\n",
    "                print('No data found')\n",
    "                return False\n",
    "            with open(infile, 'rb') as fr:\n",
    "                hdr = fr.read(300)\n",
    "                ice = np.fromfile(fr, dtype=np.uint8)\n",
    "\n",
    "            ice = ice.reshape(dimX,dimY)\n",
    "            ice = np.flipud(ice)\n",
    "            # scale it\n",
    "            data[n] = ice / 250. \n",
    "            # concentration is beween 0 to 1\n",
    "        data[data>1.0] = np.nan\n",
    "      \n",
    "        return data\n",
    "\n",
    "    def get_dates(self,time_start,time_end):\n",
    "        # does dates_u cover one year or more\n",
    "        #daily files\n",
    "        dates_u = []\n",
    "        d_no = (time_end-time_start).days +3\n",
    "        # make sure we get the bracket points\n",
    "        for dn in range(d_no):\n",
    "            d = time_start+ relativedelta(days = dn - 1)\n",
    "            infile = self.path+d.strftime('/%Y/')+\"nt_\"+d.strftime('%Y%m%d')+\"_*.bin\"\n",
    "            flist  = glob.glob(infile)\n",
    "            if len(flist) > 0:\n",
    "                infile = flist[0]\n",
    "                dates_u.append(d)\n",
    "            #if it does append dates_u\n",
    "        self.dates= dates_u\n",
    "        print(self.name+' Found '+str(np.shape(dates_u)[0])+' dates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SWH class\n",
    "class CPOM_SWH_ANTO():\n",
    "    \"\"\"\n",
    "    forcing class for the budget\n",
    "    lets the forcing load efficiently\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,ppath):\n",
    "        d0 = dt.datetime(2000,1,1)\n",
    "        self.name = 'CPOM_SWH_ANTO'\n",
    "        self.path = ppath\n",
    "        self.f_nc = Dataset(self.path)\n",
    "        self.m = self.f_nc.dimensions['x'].size\n",
    "        self.n = self.f_nc.dimensions['y'].size\n",
    "        self.time_vec = self.f_nc.variables['time'][:]\n",
    "        self.dates_all = [d0+relativedelta(days=t) for t in self.time_vec]\n",
    "# next function will take a list of dates and return an appropriately orientated arrays\n",
    "# give a \n",
    "    def get_swh(self,dates_u,verbos=False):\n",
    "        # does dates_u cover one year or more\n",
    "        #daily files\n",
    "        idx = [np.argwhere(np.array([d == du for d  in self.dates_all] ))[0,0] \n",
    "                                             for du in dates_u]\n",
    "        data = self.f_nc.variables['CryoSat2_swh'][idx].transpose(0,2,1)\n",
    "        return data\n",
    "\n",
    "    def get_dates(self,time_start,time_end):\n",
    "        # does dates_u cover one year or more\n",
    "        #daily files\n",
    "        dates_u = [d for d in self.dates_all \n",
    "                   if d >= time_start and d <= time_end]\n",
    "        self.dates = dates_u\n",
    "        print(self.name+' Found '+str(np.shape(dates_u)[0])+' dates')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SWH class\n",
    "class CPOM_SWH_ANTO():\n",
    "    def __init__(self,ppath):\n",
    "        d0 = dt.datetime(2000,1,1)\n",
    "        self.name = 'CPOM_SWH_ANTO'\n",
    "        self.path = ppath\n",
    "        self.f_nc = Dataset(self.path)\n",
    "        self.m = self.f_nc.dimensions['x'].size\n",
    "        self.n = self.f_nc.dimensions['y'].size\n",
    "        self.time_vec = self.f_nc.variables['time'][:]\n",
    "        self.dates_all = [d0+relativedelta(days=t) for t in self.time_vec]\n",
    "# next function will take a list of dates and return an appropriately orientated arrays\n",
    "# give a\n",
    "    def get_swh(self,dates_u,verbos=False,mask_ice = False):\n",
    "        # does dates_u cover one year or more\n",
    "        #daily files\n",
    "        idx = [np.argwhere(np.array([d == du for d  in self.dates_all] ))[0,0]\n",
    "                                             for du in dates_u]\n",
    "        data = self.f_nc.variables['CryoSat2_swh'][idx].transpose(0,2,1)\n",
    "        if mask_ice:\n",
    "            mask = self.f_nc.variables['mask'][idx].transpose(0,2,1)\n",
    "            data[mask==0] = np.nan\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "    def get_dates(self,time_start,time_end):\n",
    "        # does dates_u cover one year or more\n",
    "        #daily files\n",
    "        dates_u = [d for d in self.dates_all\n",
    "                   if d >= time_start and d <= time_end]\n",
    "        self.dates = dates_u\n",
    "        print(self.name+' Found '+str(np.shape(dates_u)[0])+' dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### for the full ice concentration data edit this file path\n",
    "IC = NSIDC_nt('D:\\DTdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "SWH = CPOM_SWH_ANTO('D:\\Weiyi_SWH\\SWH_anto_100k_no_bias_2011-2019.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pick a date\n",
    "date = dt.datetime(2013, 3, 26)\n",
    "#### use the above objects to get data for a single day\n",
    "aice = IC.get_aice([date])\n",
    "swh = SWH.get_swh([date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plots SWH and IC for a single day\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(1,2,1,projection=m)\n",
    "ax.set_extent([20, 90, -90, -60], ccrs.PlateCarree())\n",
    "ax.pcolormesh(GN.xpts,GN.ypts,aice[0],\n",
    "              vmin =0.0,vmax = 1.0)\n",
    "\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(1,2,2,projection=m)\n",
    "ax.set_extent([-180, -130, -90, -50], ccrs.PlateCarree())\n",
    "ax.pcolormesh(GS.xpts,GS.ypts,swh[0],\n",
    "              vmin =0.0,vmax = 10.0)\n",
    "\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pick a series of dates\n",
    "ndays = 10\n",
    "date = dt.datetime(2018, 9, 5)\n",
    "date_list = [date + relativedelta(days=d) for d in range(ndays)]\n",
    "#### use the above objects to get data for a group of days\n",
    "aice = IC.get_aice(date_list)\n",
    "swh = SWH.get_swh(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plots SWH and IC for a group of days\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = fig.add_subplot(1,2,1,projection=m)\n",
    "\n",
    "#ax.set_extent([-180, -130, -90, -50], ccrs.PlateCarree())\n",
    "ax.set_extent([160, 180, -90, -50], ccrs.PlateCarree())\n",
    "ax.pcolormesh(GN.xpts,GN.ypts,np.nanmean(aice,axis=0),\n",
    "              vmin =0.0,vmax = 1.0)\n",
    "\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "#[180, -130, -90, -60]\n",
    "\n",
    "ax = fig.add_subplot(1,2,2,projection=m)\n",
    "ax.set_extent([160, 180, -90, -50], ccrs.PlateCarree())\n",
    "#ax.set_extent([-180, -130, -90, -50], ccrs.PlateCarree())\n",
    "s=ax.pcolormesh(GS.xpts,GS.ypts,np.nanmean(swh,axis=0),\n",
    "              vmin =0.0,vmax = 10.0)\n",
    "\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "plt.colorbar(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-academy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### plot rate of change in IC\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1,projection=m)\n",
    "#ax.set_extent([160, 180, -90, -60], ccrs.PlateCarree())\n",
    "ax.set_extent([-180, -130, -90, -60], ccrs.PlateCarree())\n",
    "s = ax.pcolormesh(GN.xpts,GN.ypts,np.nanmean(np.diff(aice,axis=0),axis=0),\n",
    "              vmin =-0.1,vmax = 0.1,cmap = plt.cm.RdBu)\n",
    "\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "plt.colorbar(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee86758b",
   "metadata": {},
   "source": [
    "### make some regional masks\n",
    "#### customise these as you will\n",
    "# changing GS to GR and make new masks for the ice \n",
    "# Full souther ocean\n",
    "lon_r = [-180,180]\n",
    "lat_r = [-60,-20]\n",
    "Southern_m = GS.generate_mask_lonlat(lon_r,lat_r)\n",
    "Southern_m_ice = GN.generate_mask_lonlat(lon_r,lat_r)\n",
    "### Weddell Sea\n",
    "lon_r = [-60,20]\n",
    "lat_r = [-90,-60]\n",
    "Weddel_m = GS.generate_mask_lonlat(lon_r,lat_r)\n",
    "Weddel_m_ice = GN.generate_mask_lonlat(lon_r,lat_r)\n",
    "#### Indian ocean sector\n",
    "lon_r = [20,90]\n",
    "lat_r = [-90,-60]\n",
    "Indian_m = GS.generate_mask_lonlat(lon_r,lat_r)\n",
    "Indian_m_ice = GN.generate_mask_lonlat(lon_r,lat_r)\n",
    "#### West Pacific sector\n",
    "lon_r = [90,160]\n",
    "lat_r = [-85,-60]\n",
    "WestPacf_m = GS.generate_mask_lonlat(lon_r,lat_r)\n",
    "WestPacf_m_ice = GN.generate_mask_lonlat(lon_r,lat_r)\n",
    "#### Combining two to make the Ross sea sector\n",
    "lon_r = [160,180]\n",
    "lat_r = [-90,-60]\n",
    "Ross1_m = GS.generate_mask_lonlat(lon_r,lat_r)\n",
    "Ross1_m_ice = GN.generate_mask_lonlat(lon_r,lat_r)\n",
    "lon_r = [180,-130]\n",
    "lat_r = [-90,-60]\n",
    "Ross2_m = GS.generate_mask_lonlat(lon_r,lat_r)\n",
    "Ross2_m_ice = GN.generate_mask_lonlat(lon_r,lat_r)\n",
    "Ross_m = Ross1_m+Ross2_m\n",
    "Ross_m_ice = Ross1_m_ice+Ross2_m_ice\n",
    "#### Bellingshausena nd Admundsen Seas\n",
    "lon_r = [-130,-60]\n",
    "lat_r = [-90,-60]\n",
    "BandA_m = GS.generate_mask_lonlat(lon_r,lat_r)\n",
    "BandA_m_ice = GN.generate_mask_lonlat(lon_r,lat_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot a region mask\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1,projection=m)\n",
    "ax.set_extent([160, -130, -90, -60], ccrs.PlateCarree())\n",
    "s = ax.pcolormesh(GS.xpts,GS.ypts,Ross_m)\n",
    "\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "plt.colorbar(s)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-space",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### set a time range\n",
    "ts = dt.datetime(2017,1,1)\n",
    "te = dt.datetime(2019,5,5)\n",
    "SWH.get_dates(ts,te)\n",
    "IC.get_dates(ts,te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-parish",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ice time series for regions\n",
    "ice = IC.get_aice(IC.dates)\n",
    "Regions_ice = [\n",
    "           {'mask':Southern_m_ice,'label':'Ice concentration'}\n",
    "]\n",
    "\n",
    "for rg in Regions_ice:\n",
    "    ice_region = ice*rg['mask'][None,:,:]\n",
    "    plt.plot_date(IC.dates,np.nanmean(ice_region,axis=(1,2)),\n",
    "                  label = rg['label'],linestyle ='-',marker = '')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808ffa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SWH time series for the Sourtern Ocean \n",
    "swh = SWH.get_swh(SWH.dates,mask_ice=True)\n",
    "Regions = [{'mask':Southern_m,'label':'Significant wave height'}]\n",
    "\n",
    "for rg in Regions:\n",
    "    swh_region = swh.copy()\n",
    "    mask_region = np.ones_like(swh,dtype = bool)\n",
    "    mask_region *= rg['mask'][None,:,:]\n",
    "    swh_region[mask_region==False] = np.nan\n",
    "    \n",
    "    #swh_region = swh*rg['mask'][None,:,:]\n",
    "    plt.plot_date(SWH.dates,np.nanmean(swh_region,axis=(1,2)),\n",
    "                  label = rg['label'],linestyle ='-',marker = '')    \n",
    "        \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284258c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SWH time series for regions\n",
    "swh = SWH.get_swh(SWH.dates,mask_ice=True)\n",
    "Regions = [{'mask':Ross_m,'label':'West Pacific'}]\n",
    "\n",
    "for rg in Regions:\n",
    "    #swh_region = swh*rg['mask'][None,:,:]\n",
    "    swh_region = swh.copy()\n",
    "    mask_region = np.ones_like(swh,dtype = bool)\n",
    "    mask_region *= rg['mask'][None,:,:]\n",
    "    swh_region[mask_region==False] = np.nan\n",
    "    # FFT the signal\n",
    "    in_vec = np.nanmean(swh_region.data,axis=(1,2))\n",
    "    in_vec[np.isnan(in_vec)] = 0.0\n",
    "    \n",
    "    time = np.arange(0,len(in_vec),1)\n",
    "    W = fftfreq(len(in_vec))\n",
    "    f_signal = fft(in_vec)\n",
    "    # copy the FFT results\n",
    "    plt.subplot(121)\n",
    "    plt.plot(time,in_vec)\n",
    "    plt.xlabel('date')\n",
    "    plt.title('original signal')\n",
    "    plt.subplot(122)\n",
    "    plt.plot(W,np.abs(f_signal))\n",
    "    plt.xlabel('frequency')\n",
    "    plt.title('FFT after filtering')\n",
    "    plt.xlim(0,0.08)\n",
    "    plt.ylim(0,250)\n",
    "    plt.show()\n",
    "    f_signal2 = f_signal.copy()\n",
    "    # low pass and high pass differ \n",
    "    # this is based on the time period\n",
    "    # if it is 3 year then use the first 2 set; if it's 2 and a half use the 2nd one\n",
    "    #f_signal2[0:6] = 0.0\n",
    "    #f_signal2[220:] = 0.0\n",
    "    f_signal2[177:] = 0.0\n",
    "    f_signal2[0:5] = 0.0\n",
    "    \n",
    "    #f_signal2[100:] = 0.0\n",
    "    #ivec = ifft(f_signal)\n",
    "    ivec = ifft(f_signal2)\n",
    "    plt.plot(time,in_vec,label = rg['label'])\n",
    "    plt.plot(time,ivec, label = 'seasonal cycle removed')\n",
    "    plt.axhline(y=8, color='r', linestyle='-',label = 'SWH threshold' )\n",
    "    #plt.plot(time,3, label = 'SWH threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b288e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ice = IC.get_aice(IC.dates)\n",
    "Regions_ice = [{'mask':Ross_m_ice,'label':'West Pacific'}]\n",
    "\n",
    "for rg in Regions_ice:\n",
    "    IC_region = ice*rg['mask'][None,:,:]\n",
    "    in_vec = np.nanmean(IC_region.data,axis=(1,2))\n",
    "    in_vec[np.isnan(in_vec)] = 0.0\n",
    "    time_ice = np.arange(0,len(in_vec),1)\n",
    "    # FFT the signal\n",
    "    W = fftfreq(len(in_vec))\n",
    "    f_signal = fft(in_vec)\n",
    "    # copy the FFT results\n",
    "    plt.subplot(121)\n",
    "    plt.plot(time_ice,in_vec)\n",
    "    plt.xlabel('date')\n",
    "    plt.title('original signal')\n",
    "    plt.subplot(122)\n",
    "    plt.plot(W,np.abs(f_signal))\n",
    "    plt.xlabel('date')\n",
    "    plt.title('FFT after filtering')\n",
    "    plt.xlim(0,0.08)\n",
    "    plt.ylim(0,250)\n",
    "    plt.show()\n",
    "    # high-pass & low-pass filter \n",
    "    f_signal2 = f_signal.copy()\n",
    "    #f_signal2[0:9] = 0.0\n",
    "    #f_signal2[220:] = 0.0\n",
    "    f_signal2[177:] = 0.0\n",
    "    f_signal2[0:7] = 0.0\n",
    "    ivec_ice = ifft(f_signal2)\n",
    "    plt.plot(time_ice,in_vec,label = rg['label'])\n",
    "    plt.plot(time_ice,ivec_ice, label = 'seasonal cycle removed')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking the date\n",
    "t= np.nanmean(swh_region.data,axis=(1,2))\n",
    "for i in range (0, len(t)):\n",
    "    # finding date where SWH above threshold\n",
    "    if t[i] >9:\n",
    "        #print(t[i])\n",
    "        print(i)\n",
    "        \n",
    "        \n",
    "# finding the date where large storm event happened\n",
    "\n",
    "d0 = date(2017, 1, 1)\n",
    "d1 = date(2018, 9, 5)\n",
    "delta = d1 - d0\n",
    "print(delta.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe37a67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot out the scatter plot\n",
    "a=np.nanmean(swh_region.data,axis=(1,2))\n",
    "c=np.nanmean(ice_region.data,axis=(1,2))\n",
    "x=[]\n",
    "y=[]\n",
    "b=[]\n",
    "data_IC = np.diff(ivec_ice) / np.diff(time_ice)\n",
    "o=data_IC\n",
    "p=ivec\n",
    "\n",
    "for i in range (0,10):\n",
    "    if a[i]!=float('nan') and c[i]!=float('nan'):\n",
    "        x.append(i)\n",
    "        y.append(p[i])\n",
    "        b.append(o[i]*3000)\n",
    "        #print(a[i])\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    x, y, 'bo',\n",
    "    x, b, 'ro'\n",
    ")\n",
    "plt.legend(['SWH(filtered)', 'derivative of IC'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
